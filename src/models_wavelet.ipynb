{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection of modified images or videos using Neural Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import io\n",
    "import shutil\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import pywt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation, Input, GlobalAveragePooling2D\n",
    "from keras.applications import ResNet50, MobileNet, MobileNetV2, VGG16, Xception, EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetV2B1\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "K.clear_session()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"sophatvathana/casia-dataset\"\n",
    "PATH_DATASET = './../dataset/'\n",
    "\n",
    "def download_dataset():\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    print(\"Downloading files...\")\n",
    "    api.dataset_download_files('sophatvathana/casia-dataset', path=PATH_DATASET, unzip=True)\n",
    "\n",
    "    print(\"\\rDownload complete.\")\n",
    "\n",
    "\n",
    "def clean_directory():\n",
    "    print(\"Moving folder...\")\n",
    "    os.rename(PATH_DATASET+\"CASIA2/Au\", PATH_DATASET+\"Au\")\n",
    "    os.rename(PATH_DATASET+\"CASIA2/Tp\", PATH_DATASET+\"Tp\")\n",
    "    \n",
    "    print(\"Cleaning directory...\")\n",
    "    shutil.rmtree(PATH_DATASET+\"casia\")\n",
    "    shutil.rmtree(PATH_DATASET+\"CASIA1\")\n",
    "    shutil.rmtree(PATH_DATASET+\"CASIA2\")\n",
    "    os.remove(PATH_DATASET+\"Tp/Thumbs.db\")\n",
    "    os.remove(PATH_DATASET+\"Au/Thumbs.db\")\n",
    "    print(\"Cleaning complete.\")\n",
    "\n",
    "def remove_images():\n",
    "    print(\"Removing images...\")\n",
    "    for i in range(1, 4):\n",
    "        os.remove(PATH_DATASET+\"Au/Au (\"+str(i)+\").jpg\")\n",
    "        os.remove(PATH_DATASET+\"Tp/Tp (\"+str(i)+\").jpg\")\n",
    "    print(\"Removing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(PATH_DATASET+\"Au\"):\n",
    "    download_dataset()\n",
    "    clean_directory()\n",
    "else:\n",
    "    print(\"Dataset already Downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_IMAGE_PATH = '../dataset/Au'\n",
    "FAKE_IMAGE_PATH = \"../dataset/Tp\"\n",
    "IMG_SIZE = (256, 256)\n",
    "CLASS = [\"real\", \"fake\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabezera = \"category\", \"image\", \"class\"\n",
    "df_au = pd.DataFrame(columns=cabezera)\n",
    "df_tp = pd.DataFrame(columns=cabezera)\n",
    "\n",
    "for idx, file in enumerate(os.listdir(REAL_IMAGE_PATH)):\n",
    "    img_path = os.path.join(REAL_IMAGE_PATH, file)\n",
    "    category = file.split(\"_\")\n",
    "\n",
    "    df_au = pd.concat([df_au, pd.DataFrame([[category[1], img_path, CLASS[0]]], columns=cabezera)], ignore_index=True)\n",
    "\n",
    "for file in os.listdir(FAKE_IMAGE_PATH):\n",
    "    #convert image to np array\n",
    "    img_path = os.path.join(FAKE_IMAGE_PATH, file)\n",
    "\n",
    "    category = file.split(\"_\")\n",
    "    category[5] = category[5][:3]\n",
    "    df_tp = pd.concat([df_tp, pd.DataFrame([[category[5], img_path, CLASS[1]]], columns=cabezera)], ignore_index=True)\n",
    "\n",
    "df = pd.concat([df_au, df_tp], ignore_index=True)\n",
    "df = df[df.category != \"txt\"]\n",
    "df = df[df.category != \"ind\"]\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet(image):\n",
    "    # Convertir la imagen a escala de grises\n",
    "    gris = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Aplicar la transformada de wavelet\n",
    "    coeffs = pywt.dwt2(gris, 'haar')\n",
    "    LL, (LH, HL, HH) = coeffs\n",
    "    \n",
    "    # Aplicar la transformada inversa de wavelet\n",
    "    reconstruccion = pywt.idwt2(coeffs, 'haar')\n",
    "    \n",
    "    # Calcular la resta entre la imagen original y la reconstrucciÃ³n\n",
    "    resta = gris - reconstruccion\n",
    "    \n",
    "    # Convertir la resta a una imagen de 3 dimensiones\n",
    "    resta_3d = np.stack((resta, resta, resta), axis=2).astype(np.uint8)\n",
    "    \n",
    "    return resta_3d\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    #image = tf.cast(tensor, tf.uint8).numpy()\n",
    "    image = wavelet(image)\n",
    "    #image = preprocess_input(image)\n",
    "    return tf.convert_to_tensor(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_image,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_image,\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=df_train,\n",
    "    directory=None,\n",
    "    x_col=\"image\",\n",
    "    y_col=\"class\",\n",
    "    subset=\"training\",\n",
    "    batch_size=batch_size,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"binary\",\n",
    "    target_size=IMG_SIZE\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=df_train,\n",
    "    directory=None,\n",
    "    x_col=\"image\",\n",
    "    y_col=\"class\",\n",
    "    subset=\"validation\",\n",
    "    batch_size=batch_size,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"binary\",\n",
    "    target_size=IMG_SIZE\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=df_test,\n",
    "    directory=None,\n",
    "    x_col=\"image\",\n",
    "    y_col=\"class\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    class_mode=\"binary\",\n",
    "    target_size=IMG_SIZE\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    tf.keras.metrics.BinaryAccuracy(name='binary_accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "    tf.keras.metrics.AUC(name='prc', curve='PR')\n",
    "]\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    min_delta=0, \n",
    "    patience=10, \n",
    "    verbose=0, \n",
    "    mode='auto', \n",
    "    baseline=None, \n",
    "    restore_best_weights=False\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1)\n",
    "\n",
    "\n",
    "model_chekpoint = ModelCheckpoint(\n",
    "    filepath='./../model/checkpoints', \n",
    "    monitor='val_loss', \n",
    "    verbose=0, \n",
    "    save_best_only=True,\n",
    "    save_weights_only=True, \n",
    "    mode='auto', \n",
    "    save_freq='epoch'\n",
    ")\n",
    "\n",
    "tensor_board = TensorBoard(\n",
    "    log_dir='./../model/logs',\n",
    "    histogram_freq=0,\n",
    "    write_graph=True,\n",
    "    write_images=False,\n",
    "    update_freq='epoch',\n",
    "    profile_batch=2,\n",
    "    embeddings_freq=0,\n",
    "    embeddings_metadata=None\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, model_chekpoint, tensor_board]\n",
    "optimizer = Adam(1e-3)\n",
    "loss = keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model fron scratch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detect_manipulated_images_model_scratch_v1.h5 10min 14s 15 epocas bacth_size=32 42s\n",
    "\n",
    "loss: 0.6755 - binary_accuracy: 0.5969 - precision: 0.5969 - recall: 1.0000 - auc: 0.5000 - prc: 0.5969"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), activation=None, input_shape=(256, 256, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(5, 5), activation=None, kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(5, 5), activation=None, kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=None, kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model using transfer learning (ResNet50)\n",
    "\n",
    "detect_manipulated_images_model_resNet50.h5 21m 14s 14 epocas bacth_size=32 90s\n",
    "\n",
    "loss: 0.6753 - binary_accuracy: 0.5969 - precision: 0.5969 - recall: 1.0000 - auc: 0.5000 - prc: 0.5969"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(256, 256, 3))\n",
    "\n",
    "model = ResNet50(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "\n",
    "x = Flatten()(model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=model.inputs, outputs=predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model using transfer learning (MobileNet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detect_manipulated_images_model_mobilenet.h5 22m 5s 20 epocas bacth_size=32 67s\n",
    "\n",
    "loss: 0.6755 - binary_accuracy: 0.5969 - precision: 0.5969 - recall: 1.0000 - auc: 0.5000 - prc: 0.5969"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(256, 256, 3))\n",
    "model = MobileNet(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "x = GlobalAveragePooling2D()(model.output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=model.inputs, outputs=predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model using transfer learning (VGG16)\n",
    "\n",
    "detect_manipulated_images_model_vgg16_v1.h5 36m 15s 20 epocas bacth_size=32 108s\n",
    "\n",
    "loss: 0.6651 - binary_accuracy: 0.6180 - precision: 0.6180 - recall: 1.0000 - auc: 0.5000 - prc: 0.6180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "x = vgg16.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=vgg16.inputs, outputs=predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creatin Model Xception\n",
    "\n",
    "detect_manipulated_images_model_Xception.h5 29m 5s 11 epocas bacth_size=32 158s\n",
    "\n",
    "\n",
    "loss: 0.6055 - binary_accuracy: 0.6180 - precision: 0.6180 - recall: 1.0000 - auc: 0.5000 - prc: 0.6180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(256, 256, 3))\n",
    "model = Xception(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "x = GlobalAveragePooling2D()(model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=model.inputs, outputs=predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creatin Model EfficientNetB1\n",
    "\n",
    "detect_manipulated_images_model_EfficientNetB1.h5 31m 38s 14 epocas bacth_size=32 125s\n",
    "\n",
    "loss: 0.6684 - binary_accuracy: 0.6135 - precision: 0.6142 - recall: 0.9973 - auc: 0.4908 - prc: 0.6027\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetB1(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "\n",
    "x = GlobalAveragePooling2D()(model.output)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=model.inputs, outputs=predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "history = model.fit(train_generator, epochs=20, batch_size=batch_size, validation_data=val_generator, callbacks=callbacks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    metrics = ['binary_accuracy', 'loss', 'prc', 'precision', 'recall']\n",
    "    fig, axes = plt.subplots(len(metrics), 1, figsize=(10, 10))\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        axes[i].plot(history.history[metric], label='train')\n",
    "        axes[i].plot(history.history[f'val_{metric}'], label='val')\n",
    "        axes[i].set_title(metric)\n",
    "        axes[i].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(model, X, y_true):\n",
    "    y_pred = model.predict(X) > 0.5\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(cm, cmap=plt.cm.Reds)\n",
    "    plt.title('Confusion Matrix', fontsize=16)\n",
    "    plt.ylabel('True label', fontsize=14)\n",
    "    plt.xlabel('Predicted label', fontsize=14)\n",
    "    plt.xticks([0, 1], ['Manipulated', 'Original'], fontsize=12)\n",
    "    plt.yticks([0, 1], ['Manipulated', 'Original'], fontsize=12)\n",
    "    plt.colorbar()\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j, i, str(cm[i][j]), ha='center', va='center', fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./../model/wavelet_models/detect_manipulated_images_model_efficientNetB1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8a00227fbbeabfee3e4c7eae78ea7efab3aaaa5b33f3ff28071daefabaeab66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

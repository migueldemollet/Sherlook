{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection of modified images or videos using Neural Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.applications import EfficientNetB3\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"sophatvathana/casia-dataset\"\n",
    "PATH_DATASET = './../dataset/'\n",
    "\n",
    "def download_dataset():\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    print(\"Downloading files...\")\n",
    "    api.dataset_download_files('sophatvathana/casia-dataset', path=PATH_DATASET, unzip=True)\n",
    "\n",
    "    print(\"\\rDownload complete.\")\n",
    "\n",
    "\n",
    "def clean_directory():\n",
    "    print(\"Moving folder...\")\n",
    "    os.rename(PATH_DATASET+\"CASIA2/Au\", PATH_DATASET+\"Au\")\n",
    "    os.rename(PATH_DATASET+\"CASIA2/Tp\", PATH_DATASET+\"Tp\")\n",
    "    \n",
    "    print(\"Cleaning directory...\")\n",
    "    shutil.rmtree(PATH_DATASET+\"casia\")\n",
    "    shutil.rmtree(PATH_DATASET+\"CASIA1\")\n",
    "    shutil.rmtree(PATH_DATASET+\"CASIA2\")\n",
    "    os.remove(PATH_DATASET+\"Tp/Thumbs.db\")\n",
    "    os.remove(PATH_DATASET+\"Au/Thumbs.db\")\n",
    "    print(\"Cleaning complete.\")\n",
    "\n",
    "def remove_images():\n",
    "    print(\"Removing images...\")\n",
    "    for i in range(1, 4):\n",
    "        os.remove(PATH_DATASET+\"Au/Au (\"+str(i)+\").jpg\")\n",
    "        os.remove(PATH_DATASET+\"Tp/Tp (\"+str(i)+\").jpg\")\n",
    "    print(\"Removing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(PATH_DATASET+\"Au\"):\n",
    "    download_dataset()\n",
    "    clean_directory()\n",
    "else:\n",
    "    print(\"Dataset already Downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_IMAGE_PATH = '../dataset/Au'\n",
    "FAKE_IMAGE_PATH = \"../dataset/Tp\"\n",
    "IMG_SIZE = (256, 256)\n",
    "CLASS = [\"real\", \"modified\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabezera_au = \"category\", \"image\", \"class\"\n",
    "df_au = pd.DataFrame(columns=cabezera_au)\n",
    "\n",
    "cabezera_tp = \"category\", \"image\", \"region\", \"class\"\n",
    "df_tp = pd.DataFrame(columns=cabezera_tp)\n",
    "\n",
    "for idx, file in enumerate(os.listdir(REAL_IMAGE_PATH)):\n",
    "    img_path = os.path.join(REAL_IMAGE_PATH, file)\n",
    "    category = file.split(\"_\")\n",
    "\n",
    "    df_au = pd.concat([df_au, pd.DataFrame([[category[1], img_path, CLASS[0]]], columns=cabezera_au)], ignore_index=True)\n",
    "\n",
    "df_au = df_au[df_au.category != \"txt\"]\n",
    "df_au = df_au[df_au.category != \"ind\"]\n",
    "df_au = df_au.groupby('category').head(600)\n",
    "\n",
    "for file in os.listdir(FAKE_IMAGE_PATH):\n",
    "    #convert image to np array\n",
    "    img_path = os.path.join(FAKE_IMAGE_PATH, file)\n",
    "\n",
    "    category = file.split(\"_\")\n",
    "    category[5] = category[5][:3]\n",
    "    df_tp = pd.concat([df_tp, pd.DataFrame([[category[5], img_path, category[1], CLASS[1]]], columns=cabezera_tp)], ignore_index=True)\n",
    "\n",
    "df_tp = df_tp[df_tp.category != \"txt\"]\n",
    "df_tp = df_tp[df_tp.category != \"ind\"]\n",
    "df_tp = df_tp.groupby(['category', 'region']).head(300)\n",
    "df_tp = df_tp.drop(columns=['region'])\n",
    "\n",
    "df = pd.concat([df_au, df_tp], ignore_index=True)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ela(image, quality=99):\n",
    "    # Comprimir y descomprimir la imagen\n",
    "    _, buffer = cv2.imencode('.jpg', image, [cv2.IMWRITE_JPEG_QUALITY, quality])\n",
    "    compressed_image = cv2.imdecode(np.frombuffer(buffer, np.uint8), cv2.IMREAD_COLOR)\n",
    "\n",
    "    compressed_image = compressed_image.astype(np.float32)\n",
    "\n",
    "    diff = 15 * cv2.absdiff(image, compressed_image)\n",
    "    \n",
    "    return diff\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = ela(image)\n",
    "    return tf.convert_to_tensor(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_image,\n",
    "    validation_split=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_image,\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=df_train,\n",
    "    directory=None,\n",
    "    x_col=\"image\",\n",
    "    y_col=\"class\",\n",
    "    subset=\"training\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"binary\",\n",
    "    target_size=IMG_SIZE\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=df_train,\n",
    "    directory=None,\n",
    "    x_col=\"image\",\n",
    "    y_col=\"class\",\n",
    "    subset=\"validation\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    shuffle=True,\n",
    "    class_mode=\"binary\",\n",
    "    target_size=IMG_SIZE\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=df_test,\n",
    "    directory=None,\n",
    "    x_col=\"image\",\n",
    "    y_col=\"class\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    class_mode=\"binary\",\n",
    "    target_size=IMG_SIZE\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21 epocas 118s 41m 26s\n",
    "\n",
    "loss: 0.2441 - binary_accuracy: 0.9161 - precision: 0.9393 - recall: 0.9024 - auc: 0.9730 - prc: 0.9697"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "\n",
    "        self.base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "        self.global_pooling = GlobalAveragePooling2D()(self.base_model.output)\n",
    "        self.dense1 = Dense(2048, activation='relu')(self.global_pooling)\n",
    "        self.output_layer = Dense(1, activation='sigmoid')(self.dense1)\n",
    "\n",
    "        self.model = Model(inputs=self.base_model.inputs, outputs=self.output_layer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.model(inputs)\n",
    "    \n",
    "    def predict(self, image, grad_cam=False):\n",
    "        img_preprocessed = self._preprocess_image(image)\n",
    "        if grad_cam:\n",
    "            return self._predict_with_grad_cam(image, img_preprocessed)\n",
    "        else:\n",
    "            return super(CustomModel, self).predict(img_preprocessed)\n",
    "        \n",
    "    def _preprocess_image(self, img):\n",
    "        img = cv2.resize(img, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ela_image = ela(img)\n",
    "        img_expanded = np.expand_dims(ela_image, axis=0)  \n",
    "        return img_expanded\n",
    "\n",
    "    def _get_last_conv_layer(self):\n",
    "        for layer in reversed(self.model.layers):\n",
    "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "                return layer.name\n",
    "        return None\n",
    "    \n",
    "    def _predict_with_grad_cam(self, image, preprocess_image):\n",
    "        image = cv2.resize(image, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        grad_model = tf.keras.models.Model(\n",
    "            [self.model.inputs], [self.model.get_layer(self._get_last_conv_layer()).output, self.model.output]\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            last_conv_layer_output, preds = grad_model(preprocess_image)\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "            class_channel = preds[:, pred_index]\n",
    "\n",
    "        grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "        last_conv_layer_output = last_conv_layer_output[0]\n",
    "        heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "        heatmap = tf.squeeze(heatmap)\n",
    "        heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "        heatmap = heatmap.numpy()\n",
    "\n",
    "        heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "        # Use jet colormap to colorize heatmap\n",
    "        jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "        # Use RGB values of the colormap\n",
    "        jet_colors = jet(np.arange(256))[:, :3]\n",
    "        jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "        # Create an image with RGB colorized heatmap\n",
    "        jet_heatmap = keras.utils.array_to_img(jet_heatmap)\n",
    "        jet_heatmap = jet_heatmap.resize((image.shape[1], image.shape[0]))\n",
    "        jet_heatmap = keras.utils.img_to_array(jet_heatmap)\n",
    "\n",
    "        # Superimpose the heatmap on the original image\n",
    "        superimposed_img = jet_heatmap * 0.4 + image\n",
    "        superimposed_img = keras.utils.array_to_img(superimposed_img)\n",
    "\n",
    "        return class_channel[0].numpy(), np.array(superimposed_img)\n",
    "\n",
    "    def save_model(self, filepath):\n",
    "        os.makedirs(filepath, exist_ok=True)\n",
    "\n",
    "        # Save the model architecture and weights\n",
    "        self.model.save_weights(os.path.join(filepath, 'model_weights.h5'))\n",
    "\n",
    "        model_json = self.model.to_json()\n",
    "        with open(os.path.join(filepath, 'model_architecture.json'), 'w') as json_file:\n",
    "            json_file.write(model_json)\n",
    "    \n",
    "    @classmethod\n",
    "    def load_model(cls, filepath):\n",
    "        # Load the model architecture and weights\n",
    "        with open(filepath + '/model_architecture.json', 'r') as json_file:\n",
    "            model_json = json_file.read()\n",
    "        loaded_model = cls._from_json(model_json)\n",
    "\n",
    "        loaded_model.model.load_weights(filepath + '/model_weights.h5')\n",
    "        return loaded_model\n",
    "\n",
    "    @classmethod\n",
    "    def _from_json(cls, model_json):\n",
    "        # Create a model instance from JSON architecture\n",
    "        model = cls()\n",
    "        model.model = tf.keras.models.model_from_json(model_json)\n",
    "        return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    tf.keras.metrics.BinaryAccuracy(name='binary_accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='auc'),\n",
    "    tf.keras.metrics.AUC(name='prc', curve='PR')\n",
    "]\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    min_delta=0, \n",
    "    patience=10, \n",
    "    verbose=0, \n",
    "    mode='auto',\n",
    "    baseline=None, \n",
    "    restore_best_weights=False\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "\n",
    "model_chekpoint = ModelCheckpoint(\n",
    "    filepath='./../model/checkpoints', \n",
    "    monitor='val_loss', \n",
    "    verbose=0, \n",
    "    save_best_only=True,\n",
    "    save_weights_only=True, \n",
    "    mode='auto', \n",
    "    save_freq='epoch'\n",
    ")\n",
    "\n",
    "tensor_board = TensorBoard(\n",
    "    log_dir='./../model/logs',\n",
    "    histogram_freq=0,\n",
    "    write_graph=True,\n",
    "    write_images=False,\n",
    "    update_freq='epoch',\n",
    "    profile_batch=2,\n",
    "    embeddings_freq=0,\n",
    "    embeddings_metadata=None\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping, tensor_board]\n",
    "optimizer = Adam(learning_rate=1e-3)\n",
    "loss = keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epochs = 20\n",
    "fine_tune_epochs = 30\n",
    "total_epochs =  initial_epochs + fine_tune_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomModel()\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    # Obtener las métricas de entrenamiento\n",
    "    loss = history.history['loss']\n",
    "    accuracy = history.history['binary_accuracy']\n",
    "    \n",
    "    # Obtener las métricas de validación si están disponibles\n",
    "    if 'val_loss' in history.history:\n",
    "        val_loss = history.history['val_loss']\n",
    "        val_accuracy = history.history['val_binary_accuracy']\n",
    "        has_validation = True\n",
    "    else:\n",
    "        has_validation = False\n",
    "    \n",
    "    # Crear los subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "    \n",
    "    # Plot de la pérdida\n",
    "    ax1.plot(loss, label='Training Loss')\n",
    "    if has_validation:\n",
    "        ax1.plot(val_loss, label='Validation Loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot de la precisión binaria\n",
    "    ax2.plot(accuracy, label='Training Accuracy')\n",
    "    if has_validation:\n",
    "        ax2.plot(val_accuracy, label='Validation Accuracy')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Mostrar el gráfico\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../dataset/Tp/Tp_D_CRD_S_O_ani10103_ani10111_10637.jpg'\n",
    "img = cv2.imread(path)\n",
    "md = load_model(\"./../model/ela_models/detect_manipulated_images_model_EfficientNetB2.h5\")\n",
    "model = CustomModel()\n",
    "model.model = md\n",
    "y_pred, img_heamap = model.predict(img, grad_cam=True)\n",
    "\n",
    "img = cv2.resize(img, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(ela(img))\n",
    "plt.title('prepocessing Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(img_heamap)\n",
    "plt.title('Superimposed Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../dataset/test/me_x_3.jpg'\n",
    "img = cv2.imread(path)\n",
    "\n",
    "y_pred, img_heamap = model.predict(img, grad_cam=True)\n",
    "\n",
    "img = cv2.resize(img, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(ela(img))\n",
    "plt.title('prepocessing Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(img_heamap)\n",
    "plt.title('Superimposed Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('../model/custom_models/EfficientNetB3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8a00227fbbeabfee3e4c7eae78ea7efab3aaaa5b33f3ff28071daefabaeab66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
